<h1>C.  J1 Machine Forth Compiler/Assembler</h1>
<p>Most commonly known microprocessors utilize random-access registers to hold onto data currently being worked on.  Thus, to realize a Forth programming environment, a virtual machine must be programmed implementing the desired Forth machine characteristics.  This may take the form of a rather complex compiler able to convert stack machine instructions into well-optimized host machine code, or it might function more-or-less as a dumb macro assembler of sorts, stringing together pieces of code known to function in a desired stack-machine manner.  The former case trades in complexity of implementation to deliver speed of execution, while the latter trades in runtime performance for implementation simplicity.  Finding a solution which allows both implementation simplicity and good run-time performance seems impossible with traditionally known processor architectures.</p>
<p>The J1 microprocessor, however, interprets an instruction set that implements a physical Forth machine.  In essence, one J1 instruction corresponds to one Forth instruction, with only a small set of exceptions.  Because of this, the machine language of the processor is known as <i>machine Forth.</i>  The sections that follow documents the assembler/compiler's implementation.</p>

<<asm.f>>=
<<GForth compatibility layer>>
<<Target Dictionary>>
<<Comma Compiler>>
<<Symbol Table>>
<<Deferred words>>
<<Colon Compiler>>
<<Macros>>
<<[[TARGET]] and [[HOST]]>>
host definitions
@ </p>

<h2>C.1  Target Dictionary Space</h2>
<p>When compiling to the J1, we need some place to put the instructions.  Although the J1 processor can address 64KiB of memory, the instruction pointer register contains only 13 changeable bits (bit 0 is always 0).  Thus, the J1 can only execute instructions from the first 16KiB of space.  This imposes a convenient upper limit on the target image.  Most computers contain significantly more than 64KiB of memory, so we can just embed the entirety of the image in the host Forth dictionary.</p>

<<Target Dictionary>>=
16384 constant /image
create image
/image allot

@ During the course of compiling software, we make frequent references into target memory space.  We want to ensure that we don't spill over into host memory when doing so.  Accessing any cell or byte not belonging to the target is strictly an error, and will result in immediate termination of the compiler.  We catch errors during target address to host address translation.</p>

<<Target Dictionary>>=
: -small    dup 0< abort" Target address out of range." ;
: -big      dup /image >= abort" Target address out of range." ;
<<Odd address check>>
: >host     -small -big -odd image + ;

@ The J1, when presented with an odd address, continues to fetch or store from/to the word as though bit 0 of the address is clear.  In other words, the J1 <i>ignores</i> bit 0 of any memory address.  However, while compiling, we want to catch references to odd addresses as errors, to ensure proper compiler function.</p>

<<Odd address check>>=
: -odd      dup 1 and abort" Attempt to access cell with an unaligned address." ;

@ Most host computers will have at least 32-bit wide data buses and register widths.  Many, as I type this, may even have 64-bit wide registers.  However, the J1 processor works with 16-bit words.  Thus, to better emulate how the J1 will be referencing memory, we would like to use a variant of [[@]] and [[!]] that constrains its data to 16 bits.  ANS Forth provides no such support, so we synthesize our own using [[C@]], [[C!]], and a bit of bit-shifting logic.  Note, for this code to work, we must assume that [[C@]] and [[C!]] works with 8-bit bytes.  Thus, this code will break on ANS Forth systems with a 16-bit wide character.</p>

<<Target Dictionary>>=
: w@        dup c@ 8 lshift swap 1+ c@ 255 and or ;
: w!        over 8 rshift over c! 1+ c! ;
: t@        >host w@ ;
: t!        >host w! ;

@ After compilation is complete, we want to output the binary image so the Kestrel emulator can import it upon startup.  Note that we emit the data to a file named [[romfile]]; altering the filename requires changing the definition of [[open]], below.  However, notice that the Kestrel-2 emulator software expects the ROM image to appear in a file called [[romfile]], so it's probably better to just use shell tools to rename your images as appropriate.</p>

<<Target Dictionary>>=
variable        h
: open          S" romfile" r/w bin create-file throw h ! ;
: close         h @ close-file throw ;
: write         image 16384 h @ write-file throw ;
: romfile       open write close ." romfile created/updated." cr ;

@ </p>
<h2>C.2  Comma Compiler</h2>
<p>Compilation involves laying down words corresponding to the source text in target space in the order they're found.  Words can be determined by the compiler (in the case of calls to other words or optimizations to control flow), or they may be explicitly specified by the user (in the case of statically declared data structures or literals).  In Forth, all forms of compilation ultimately builds on [[,]], the lowest-level compiler.  For [[,]] to work, we need to maintain a pointer, sometimes called a <i>compilation pointer</i>, in a variable [[cp]].</p>

<<Comma Compiler>>=
variable cp

@ When compiling a program, we need to know where to start compilation.  The [[org]] directive informs the assembler where the next instruction should be placed in target memory.</p>

<<Comma Compiler>>=
: org       cp ! ;

@ While [[org]] has its place, usually at the beginning of the source listing, querying the compilation pointer occurs frequently enough to deserve its own name.  [[here]] serves this purpose in the host Forth environment; however, we need a different word to describe the same concept in the context of the target.  Somewhat amusingly, English has just such a word, [[there]], which can be read either as <i>there</i> or as <i>target-here</i>.</p>

<<Comma Compiler>>=
: there     cp @ ;

@ Which now brings us to the lowest level compilation primitives.  In a host Forth environment, [[allot]] adjusts the compilation pointer so as to either reserve or free dictionary space.  We define [[tallot]] to serve the corresponding role in target-space.</p>

<<Comma Compiler>>=
: tallot    cp +! ;
<<Target names>>=
: allot         tallot ;

@ Placing data in the target image then becomes a matter of stuffing a word into target space, and reserving the space consumed.  We use the symbol [[,,]] instead of [[t,]], which I suppose is what most would expect of a primitive affecting target space, because it's more convenient to type.  Later, when we implement the [[host]] and [[target]] words, we'll see how we cover this up, so that the user of the compiler never needs to know when to use [[,]] versus [[,,]].  To the user, it's always [[,]].</p>

<<Comma Compiler>>=
: ,,        there t!  2 tallot ;
<<Target names>>=
: ,             ,, ;

@ </p>

<h2>C.3  Symbol Table</h2>
<p>While compiling a word, we refer to other previously compiled words or to primitives.  To compile references to previously compiled words, we need to know their target addresses.  Therefore, we need a <i>symbol table</i>, a database of (name, address) pairs.</p>
<<Symbol Table>>=
<<Symbol Table Name String Buffer>>
<<Symbol Table Name String Buffer Invariant Check>>
<<Symbol Table Name Intern Logic>>
<<Symbol Database Table>>
<<Symbol Database Table Reset Logic>>
<<Symbol Table Definition Support>>
<<Symbol Table Definition Logic>>
<<Symbol Table Attribute Accessors>>
<<Symbol Table Query Support>>
<<Symbol Table Query Logic>>

@ The symbol table consists of two aggregate components.  First, we have a chunk of storage space reserved for storing the names we encounter.  We need this because Forth lacks any support for strings out of the box.  Second, we need the database table itself.</p>

<h3>C.3.1  Name String Buffer</h3>
<p>As the compiler finds new names to define, the bytes comprising the names are stored one after the other in this string buffer.  Since the J1 can execute instructions only from the first 16KiB of memory, and considering most Forth applications have an <i>average</i> word definition length of eight words (16 bytes), we need enough space to hold at most (16 384&div;16)=1 024 definition names.  Due to my particular coding style, I predict the average name length to fall between two and three characters, so to start with, I'll make the string buffer 2&times;1 024=2 048 bytes, and increase it only if I need to.</p>

<<Symbol Table Name String Buffer>>=
2048 constant /buffer
create strs     /buffer allot

@ When we want to remember a name, we need to make sure that we store the data inside our [[strs]] buffer.  But, it's possible to use so many names that we overflow the buffer.  We need to maintain and enforce some invariants to protect the surrounding host memory, thus preventing the program from crashing in non-obvious ways.  Instead, we make the issue patently known to the user, and abort compilation immediately.</p>

<<Symbol Table Name String Buffer>>=
strs /buffer + constant strs)

<<Symbol Table Name String Buffer Invariant Check>>=
: invariant     sp @ strs u< abort" String pointer too small"
                sp @ strs) u< 0= abort" String pointer out of bounds" ;

@ We see our first use of a pointer into our string name space, [[sp]].  Initially, [[sp]] points at the base of [[strs]], but as the compiler remembers names, it increases towards [[str)]].  If a string is too big to remember, we inform the user and abort the compilation, again with the intent to protect our memory resources.</p>

<<Symbol Table Name String Buffer>>=
variable sp

<<Symbol Table Name String Buffer Invariant Check>>=
: +fits         sp @ over + strs) u< 0= abort" String too big to intern" ;

@ As you might imagine, remembering a string involves copying it into the [[strs]] buffer.</p>
<<Symbol Table Name Intern Logic>>=
: remembered    invariant +fits sp @ swap dup sp +! move invariant ;

@ </p>
<h3>C.3.2  Symbol Database Table</h3>
<p>We use a set of parallel arrays to store our symbol relations, including name addresses and lengths, whether or not a word is flagged as <q>immediate</q>, etc.  Notice that I size [[/column]] according to the worst-possible case, namely all one-character names, by reserving one array slot per byte of the name string buffer.  This guarantees that, as long as [[strs]]&le;[[sp]]&lt;[[strs)]], then we can never overflow the symbol database table either.</p>

<<Symbol Database Table>>=
/buffer cells constant /column
create names        /column allot
create lengths      /column allot
create addresses    /column allot
create immediacies  /column allot

@ When the target compiler first compiles on the host, we cannot be sure of its initial state.  The user's program listing must reset the symbol table state explicitly as part of its boiler-plate procedures.  After resetting the symbol table, the compiler will not be aware of any symbols at all, so make sure you invoke it only at the start of your program listing.</p>

<<Symbol Database Table Reset Logic>>=
: 0symtab       0 >symtab !  0 >visible !  strs sp ! ;

@ The [[>symtab]] variable knows the next row in which to start filling in data.  [[>visible]] always lags behind [[>symtab]], indicating the most recently defined word which is visible to the compiler.  Remember that Forth allows redefinition of words, a la:</p>
<pre>: foo  ." Hello " ;
: foo  cr foo ." World!" cr ;
</pre>
<p>In order to compile the second instance of [[foo]], Forth must somehow <q>know</q> that the [[foo]] after the [[cr]] instruction refers to the preceding definition, not the current definition.  The target compiler supports this by always ensuring that [[>symtab]]&ge;[[>visible]] at all times.  That way, [[>symtab]] might point to the second definition of [[foo]], while [[>visible]] refers to a set of words containing only the first.</p>

<<Symbol Database Table>>=
variable >symtab
variable >visible
@ </p>

<h3>C.3.3  Defining Symbols</h3>
@ Creating a definition requires associating a name with some datum, specifically a definition's address.  However, because we cannot trust the calling program to keep its string memory around for the lifetime of the definition, we must copy it into a temporary location.  This creates the invariant that all pointers in the names column point into the [[strs]] buffer.  When creating a new definition, we assume the immediacy flag is clear.  This preserves ANS Forth semantics.  Further, we assume the definition will equal the current compilation pointer.</p>

<<Symbol Table Definition Logic>>=
: defined       +opening dup l! sp @ n! remembered there a! 0 i! 1 >symtab +! ;

@ Definitions can be made only if we have enough room in the table to store the association.</p>

<<Symbol Table Definition Support>>=
: #syms         >symtab @ ;
: ofs           #syms cells ;
: +opening      ofs /column u< 0= abort" Too many symbols" ;

@ Assuming that's the case, we store the location of the name in the [[strs]] buffer that the name appears at.</p>

<<Symbol Table Definition Support>>=
: l!            ofs lengths + ! ;
: n!            ofs names + ! ;

@ We store the address where the definition appears.</p>

<<Symbol Table Definition Support>>=
: a!            ofs addresses + ! ;

@ Finally, we store the immediate flag, which defaults to [[0]] (false) per the definition of [[defined]].</p>

<<Symbol Table Definition Support>>=
: i!            ofs immediacies + ! ;

@ Notice that [[ofs]] evaluates to the byte offset inside any table column where the next cell will be placed.</p>

<h3>C.3.4  Querying Symbols</h3>

<p>Given a name on the stack, we'd like to find out if it's defined.  We define a word as <q>defined</q> if it has an associated <i>execution token</i>.  In our compiler, we let the row index serve as the execution token.  But, if it's not found, we expect a [[0]] result.  [[sfind,]] searches through all unsmudged words, while [[sfindAll,]] includes smudged words as well.</p>

<<Symbol Table Query Logic>>=
: sfind,        #visible -exist 0 ;
: sfindAll,     #syms -exist 0 ;

@ Only the starting row in the symbol table distinguishes the two.</p>

<p>Often, we only care about whether or not a symbol actually exists, not what its corresponding attributes are.  We can define a boolean predicate, checking for the existence of a corresponding execution token.</p>
<<Symbol Table Query Logic>>=
: isDefined?    sfindAll, dup 0= if nip then nip ;

@ The most common query developers make involves asking the compiler for a target word's execution token at compile-time.  It's not so convenient to invoke [[sfind,]] directly, and moreover dangerous, for [[sfind,]] remains an implementation detail subject to change in a future release of the software, so a parsing word encapsulates the desired behavior.</p>

<<Symbol Table Query Logic>>=
: token         32 word count ;
: ',            token sfind, 0= abort" Undefined" ;
<<Target names>>=
: '             ', ;

@ We search for a word starting at the most recently defined word and work our way backwards through the table, towards the first-defined word.  [[-exist]] asserts that our desired word doesn't exist.  However, if we discover the word, we return its execution token (table row index) in [[-match]].  Note that we require some address arithmetic, which is factored into [[rows]].  Anyone porting this software to a different architecture must adjust [[rows]] for his/her machine.</p>

<<Symbol Table Query Support>>=
: cell-         [ -1 cells ] literal + ;
: rows          2/ 2/ ;     ( MACHINE SPECIFIC )
: -end          dup 0 >= if exit then  drop r> drop ;
: differs?      >r 2dup r@ n@ r@ l@ compare r> swap ;
: -match        differs? if exit then  nip nip rows -1 2r> 2drop ;
: -exist        1- cells begin -end -match cell- again ;

@ [[differs?]] and other words often query certain attributes of words previously defined.  For example, the word's name:</p>

<<Symbol Table Attribute Accessors>>=
: l@            lengths + @ ;
: n@            names + @ ;

@ Individual fields of a row can be queried as well.</p>

<<Symbol Table Attribute Accessors>>=
: length        cells l@ ;
: name          cells dup n@ swap l@ ;
: definition    cells addresses + @ ;
: isImmediate?  cells immediacies + @ ;
<<Target names>>=
: >body         definition ;

@ Unsmudging a word involves exposing it to the world, which we do by adjusting the fence-post behind which all words are considered defined.</p>

<<Symbol Table Attribute Accessors>>=
: #visible      >visible @ ;
: isVisible?    #visible u< ;
: revealed      #syms >visible ! ;

@ </p>
<h2>C.4  Deferred Words</h2>
<p>When the J1 commences instruction execution for the first time, it assumes that the first instruction appears at address [[$0000]].  Forth, however, requires subroutines, constants, and variables to be defined prior to their use, leading to higher-level code coming <i>later</i> in the instruction stream, rather than before.  Therefore, first instruction executed by the J1 processor must be a JMP to the actual start-up code.  This permits an arbitrarily complex program to be compiled, while presenting a consistent interface to the hardware.</p>
<p>Forth strongly prefers early binding, meaning it tries hard to resolve addresses as soon in the development cycle as possible.  To implement the intended forward reference while still preserving Forth's early binding semantics, we need to trick it.  [[DEFER]] is a Forth constructor that binds a name to word consisting exclusively of a single jump instruction.  When subsequent Forth code wants to invoke the services of the deferred word, we invoke by name, like any other.  This satisfies Forth's early-binding behavior while providing the flexibility of defining behavior at some point later in the code.</p>

<<Deferred words>>=
: defer,        token defined revealed 0 ,, ;

<<Target names>>=
: defer         defer, ;

@ Calling a deferred word incurs only one level of indirection in run-time overhead (1 cycle on the J1 CPU).  Using deferred words, we can actually create vector tables in memory, like so:</p>
<pre>0 org
defer   _reset
defer   _timerIRQ
defer   _illegalInstruction
</pre>

<p>We would define implementations for these handlers as any other Forth word.</p>
<pre>
: irqHandler    blort blort blort ;
: reset         blah blah blah ;
</pre>

<p>However, the compiler remains unaware that [[reset]] is intended to fill the [[_reset]] vector, or that [[irqHandler]] should be invoked when the hardware's [[_timerIRQ]] vector is invoked.  The compiler provides compile-time binding of the vector's name to its jump instruction; however, we must explicitly provide the semantics of these deferred words using the [[IS]] word.</p>
<pre>
' reset is _reset
' irqHandler is _timerIRQ
' reset is _illegalInstruction
</pre>
<p>[[IS]] works by <i>patching</i> the image of the deferred word so that its jump target points to the correct program code.</p>

<<Deferred words>>=
: +even         dup 1 and abort" Odd address" ;
: +range        dup $4000 u< 0= abort" Address outside of range CPU can execute" ;
: +address      +even +range ;
: is,           definition +address 2/ ', definition t! ;
<<Target names>>=
: is            is, ;

@ </p>
<h2>C.5  Colon Compiler</h2>
<p>Forth programs consist of references to smaller and/or lower-level Forth programs, in some way or another.  The [[:]] word exists to let a programmer define new functionality in terms of existing code.  Such definitions are known as <i>colon definitions.</i></p>
<p>The colon compiler is actually an interpreter unto itself, albeit a specialized one.</p>
<<Colon Compiler>>=
<<Name Definition Logic>>
<<Subroutine Assembler>>
<<Numeric Literal Conversion Logic>>
<<Word Classification Logic>>
<<Compiler Loop Control>>

@ </p>
<h2>C.5.1  Main Loop</h2>

<<Compiler Loop Control>>=
<<Definition of [[?refill]]>>
<<Definition of [[],]]>>
<<Definition of [[:,]]>>
<<Definition of [[[,]]>>
<<Definition of [[(;)]]>>
<<Definition of [[;,]]>>

@ The colon compiler works by associating the current compilation pointer with a new symbol, and then enters the compiling loop.</p>
<<Definition of [[:,]]>>=
: :,            (:) ], ;

<<Target names>>=
: :             :, ;

@ We bind the new definition name.</p>
<<Name Definition Logic>>=
: (:)           token defined ;

@ The main compiling loop resembles the Forth outer interpreter in many respects.  It will attempt to compile words forever, until something outside the loop breaks the control flow.</p>
<<Definition of [[],]]>>=
: ],            begin ?refill token classify execute again ;
<<Target names>>=
: ]             ], ;

@ Without [[?refill]], we couldn't handle multi-line definitions.  We wish to invoke [[REFILL]] when we reach the end of the current input buffer, which causes Forth to read in the next chunk of source input.</p>

<<Definition of [[?refill]]>>=
: +eotib        >in @ source nip < if r> drop then ;
: +successful   0= abort" Unexpected end of input" ;
: ?refill       +eotib refill +successful ;

@ After you've completed the definition, terminating the compiler may be done with the [[;,]] word.</p>
<<Definition of [[;,]]>>=
: ;,            [, (;) ;

<<Target names>>=
: ;             ;, ;

@ This works just the opposite of [[:,]]; we abort from the compiler loop by breaking its return stack frame,</p>
<<Definition of [[[,]]>>=
: [,            r> r> drop >r ;  ( break out of the infinite loop set up by ] )
<<Target names>>=
: [             [, ;

@ and then tieing up any loose-ends that remain with the word's definition.  In particular, we want to ensure that we compile a return-from-subroutine call, and unsmudge the word's name.</p>
<<Definition of [[(;)]]>>=
: (;)           exit, revealed ;

@ </p>
<h2>C.5.2  Classifying Words</h2>
<<Word Classification Logic>>=
<<Definition of [[-compiled]]>>
<<Definition of [[-immediate]]>>
<<Definition of [[-number]]>>
<<Definition of [[classify]]>>

@ The compiler needs to take some kind of action for every word it sees.  The [[classify]] word ultimately decides how to handle each kind of word it sees.  When it finishes, [[classify]] needs to leave the execution token of the word's handler on the top of the data stack (whatever parameters are necessary should be placed below the execution token, of course).  As I write this, the compiler can work with three different kinds of words.  If more types of words are needed, altering [[classify]] and adding additional predicates, such as those shown below, should be sufficient to extend the cross-compiler arbitrarily.</p>

@ After grabbing the next input token, the compiler works to classify the kind of word it's dealing with.  If it's not anything the compiler can recognize, we abort the compilation with an error message.</p>
<<Definition of [[classify]]>>=
: classify      -compiled -immediate -number ." Error: " type -2 abort" Undefined" ;

@ If the word is a previously compiled colon definition, then we need to compile a subroutine call to that word's definition.</p>
<<Definition of [[-compiled]]>>=
: -compiled     2dup sfind, if nip nip definition ['] call, r> drop exit then 2drop ;

@ If the word is an immediate word, such as a host-defined primitive like [[IF]] or [[WHILE]], then we need to invoke the word right away, before moving on through the source.  We express this by making each immediate word its own handler.  Note that immediate word handlers generally take no parameters on the data stack.  I can think only of [[lit,]] as the sole exception to this rule of thumb.</p>
<<Definition of [[-immediate]]>>=
: -immediate    2dup sfind if nip nip r> drop exit then 2drop ;

@ If the word is a number, such as a literal like [[42]] or a hexadecimal literal like [[$0C]], it should be translated to some canonical form and compiled as a numeric literal.</p>
<<Definition of [[-number]]>>=
: -number       0 nn ! 2dup -dec -hex 2drop ;

@ </p>

<h2>C.5.3  Numeric Literals</h2>
@ As I write this document, only decimal and hexadecimal literals work.</p>
<<Numeric Literal Conversion Logic>>=
<<Definition of [[nn]]>>
<<Definition of [[invert,]]>>
<<Definition of [[bits14:0,]]>>
<<Definition of [[+ve]]>>
<<Definition of [[lit,]]>>
<<Decimal Number Conversion>>
<<Hexadecimal Number Conversion>>

@ We'll consider decimal numbers first,</p>
<<Decimal Number Conversion>>=
<<Definition of [[>bin]]>>
<<Definition of [[-eoi]]>>
<<Definition of [[accum]] (decimal)>>
<<Definition of [[declit]]>>
<<Definition of [[-dec]]>>

@ followed by hexadecimal numbers later.</p>
<<Hexadecimal Number Conversion>>=
<<Definition of [[+hex]]>>
<<Definition of [[accum]] (hexadecimal)>>
<<Definition of [[hexlit]]>>
<<Definition of [[-hex]]>>

@ </p>
<h3>C.5.3.1  Decimal Literals</h3>
@ If a word starts with a character between 0 and 9, heuristically, there's a great chance that it will be a decimal literal.</p>
<<Definition of [[-dec]]>>=
: is0-9?        [char] 0 [char] 9 1+ within ;
: -dec          over c@ is0-9? if declit nn @ ['] lit, 2r> 2drop then ;

@ We need an accumulator variable to hold onto the number we just converted.</p>
<<Definition of [[nn]]>>=
variable        nn

@ Conversion of a number proceeds character-by-character until we've finished the symbol.</p>
<<Definition of [[declit]]>>=
: declit        begin -eoi over c@ accum 1 /string again ;

@ We know we're at the end of input when we've reached the token's maximum length, and that means zero characters left in the input string.</p>
<<Definition of [[-eoi]]>>=
: -eoi          dup 0= if 2drop 2drop r> drop then ;

@ We accumulate each character we find, provided it's a valid digit.  With each new digit, we multiply our current knowledge of the literal by ten, and add in the current digit.</p>
<<Definition of [[accum]] (decimal)>>=
: +dec          dup 0 10 within 0= if 2r> 2drop r> drop then ;
: accum         >bin +dec nn @ 10 * + nn ! ;

@ Each digit comes in via a character code, which we need to convert to binary for accumulation to work correctly.</p>
<<Definition of [[>bin]]>>=
: >bin          [char] 0 - dup 10 u< 0= 7 and - ;

@ Although we're discussing conversion of decimal numbers right now, observe that [[>bin]]'s definition will actually work for numeric bases as large as 36, provided we use the ASCII character set.  Observe that it ignores case completely, though.  A hexadecimal number such as [[$0c]] will yield a value markedly different than [[$0C]], because the character code for <q>c</q> will differ from the character code for <q>C</q>.  That's OK, though; the [[+dec]] word ensures we never pass a non-decimal digit into [[>bin]].  Below, you'll see that the hexadecimal conversion code similarly filters its input so that all hexadecimal symbols are consistently uppercase before calling [[>bin]] as well.  Thus, [[>bin]] need not concern itself with error handling.</p>

@ After the compiler translates the number into a binary form it can work with, it must be placed into the current program's instruction stream.  The J1 can load a 15-bit positive constant in a single instruction, and a 16-bit signed value in two (the 15-bit 1's compliment, followed by an instruction to invert all the bits).  Assuming we've accumulated a positive number, we simply drop the load-constant instruction.</p>
<<Definition of [[lit,]]>>=
: lit,          +ve bits14:0, ;

@ If it's not positive, however, we need to emit a two-instruction sequence, as described above.</p>
<<Definition of [[+ve]]>>=
: +ve           dup $8000 and if invert bits14:0, invert, r> drop then ;

@ The J1 instruction to load an immediate value has the top bit set, with bits 14...0 containing the lower 15-bits of the value to load.</p>
<<Definition of [[bits14:0,]]>>=
: bits14:0,     $8000 or i, ;

@ If necessary, a second instruction to invert the bits of the top of stack is emitted.</p>
<<Definition of [[invert,]]>>=
: invert,       $6600 i, ;
<<Target names>>=
: invert        invert, ;


@ </p>
<h3>C.5.3.2  Hexadecimal Literals</h3>

@ The target compiler presently lacks the typical Forth variable [[BASE]] to indicate how it should convert numbers.  Therefore, we rely on prefixes to provide this information.  It turns out to be more convenient anyway.  Borrowing from the PDP-11, Motorola, and Western Design Center conventions, we identify hexadecimal numbers with a [[$]] prefix.</p>
<<Definition of [[-hex]]>>=
: -hex          over c@ [char] $ = if 1 /string hexlit nn @ ['] lit, 2r> 2drop then ;

@ Once we're satisfied we've identified a hexadecimal numeric literal, we consume it character-by-character, just as with decimal numbers.</p>
<<Definition of [[hexlit]]>>=
: hexlit        begin -eoi over c@ accum 1 /string again ;

@ When accumulating hexadecimal digits, we need to convert them to uppercase first, making the characters [[a b c d e f]] and [[A B C D E F]] consistent.  This lets the programmer write a number either as [[$deadbeef]], [[$DEADbeef]], [[$dEaDbEeF]], or [[$DEADBEEF]], all referring to the same number.</p>
<<Definition of [[accum]] (hexadecimal)>>=
: ucase         dup [char] a [char] z 1+ within $20 and xor ;
: accum         ucase >bin +hex nn @ 16 * + nn ! ;

@ The moment we find a character which <i>isn't</i> a hexadecimal number, return whatever value is left in [[nn]], which you'll recall from the previous section is the binary form of the number we're translating.</p>
<<Definition of [[+hex]]>>=
: +hex          dup 0 16 within 0= if 2r> 2drop r> drop then ;




@ </p>
<h2>C.5.4  Compiling Subroutine Calls and Returns</h2>
<p>Nothing can happen in a Forth environment without subroutines.  Coded as words, subroutines form the basic unit of code re-use.  Indeed, it is the subroutine which truly distinguishes software from hardware.</p>
<<Subroutine Assembler>>=
<<Instruction placement>>
<<Definition of [[return,]]>>
<<Definition of [[+bb]]>>
<<Definition of [[+here>=2]]>>
<<Definition of [[pInsn]]>>
<<Definition of [[-call?]]>>
<<Definition of [[tweak]]>>
<<Definition of [[>jmp]]>>
<<Definition of [[-call]]>>
<<Definition of [[-alu?]]>>
<<Definition of [[-alu]]>>
<<Definition of [[exit,]]>>
<<Definition of [[+address]]>>
<<Definition of [[call,]]>>

@ The J1 encodes calls to other Forth words by setting the top-most three bits of the instruction to [[010]], leaving the remaining 13 bits to hold the <i>word address</i> of the subroutine's definition.</p>
<<Definition of [[call,]]>>=
: call,         +address 2/ $4000 or i, ;

@ It follows that we should issue an error to the user if the compiler discovers we're trying to call a Forth word ostensibly outside of the J1's allowable program space.</p>
<<Definition of [[+address]]>>=
: +even         dup 1 and abort" Odd address" ;
: +range        dup $4000 u< 0= abort" Attempt to call word outside of CPU executable space" ;
: +address      +even +range ;

@ Subroutines terminate with the [[EXIT]] primitive.  We could naively compile a return-from-subroutine instruction; however, it won't run as fast.  The J1 instruction set has special support for same-cycle subroutine returns, which the Kestrel exploits to ensure deeply-nested colon definitions consume as little time as possible managing the return stack.  However, not all instructions have this support.  For instance, if we're inside a basic block, and the previous instruction compiled is not a [[call]] or some ALU instruction, then we need to compile an explicit subroutine return instruction.</p>
<<Definition of [[exit,]]>>=
: exit,         +bb -call -alu return, ;
<<Target names>>=
: exit          exit, ;

@ Return instructions are encoded as no-operation ALU instructions which adjust the return stack properly, and with the subroutine-return bit set.</p>
<<Definition of [[return,]]>>=
: return,       $700C p, ;

@ The compiler maintains a flag variable to record whether or not it's presently working with a basic block.
<<Instruction placement>>=
variable bb ( true if inside a basic block )

@ Regardless of what state we're in, if we're not compiling inside a basic block, then we <i>always</i> compile a subroutine return instruction.  This condition most likely occurs when the subroutine return instruction is itself a target for another branch instruction.</p>
<<Definition of [[+bb]]>>=
: +bb           bb @ if exit then return, r> drop ;

@ We know whether we're in a basic block or not based on the kind of CPU instruction we just placed in the image.  [[i,]] places an instruction of some kind with the knowledge that we're in a basic block, while [[p,]] does the same but terminates any currently open basic block.  Think of [[p,]] as a <i>program flow</i> placement primitive, while [[i,]] works for all other instructions.</p>
<<Instruction placement>>=
: p,            ,, bb off ;  ( program flow appendage )
: i,            ,, bb on ; ( anything else appendage )

@ Although we discuss [[p,]] and [[i,]] in the context of compiling subroutines, these words will be used elsewhere in various other contexts.</p>

@ When compiling [[EXIT]], we can convert a previously occuring subroutine call into an unconditional jump.  This conserves return stack resources, permitting tail-call optimization, and the looping constructs it enables.</p>
<<Definition of [[-call]]>>=
: -call         +here>=2 pInsn -call? if exit then >jmp r> drop ;

@ If we're compiling code at location [[$0000]], what does <i>previous instruction</i> mean?  One solution simply would wrap the inspection to [[$3FFE]], but the value stored in that location could well be garbage at the time compilation begins.  I prefer to take a safer route; instead of wrapping, we just <i>arbitrarily assume</i> a previous instruction to whatever is placed in location [[$0000]] can <i>never</i> be a call instruction.</p>
<<Definition of [[+here>=2]]>>=
: +here>=2      there 2 u< if r> drop then ;

@ The previous instruction, then, is whatever appears in memory just one word before the current compilation pointer.</p>
<<Definition of [[pInsn]]>>=
: pInsn         there 2 - t@ ;

@ It's a [[CALL]] instruction if the top three bits are [[010]], as discussed earlier.</p>

<<Definition of [[-call?]]>>=
: -call?        $E000 and $4000 xor ;

@ If a previous instruction does turn out to be a subroutine call, we can convert it to an unconditional jump by clearing bit 14 of the instruction.</p>

<<Definition of [[>jmp]]>>=
: >jmp          pInsn $4000 xor tweak ;

@ Observe that if we just compiled a return instruction, we cannot possibly in a basic block.  Thus, after adjusting the image, we clear the [[bb]] flag.</p>
<<Definition of [[tweak]]>>=
: tweak         there 2 - t! bb off ;

@ What happens if we try compiling an [[EXIT]] immediately after some ALU operation?  It turns out all ALU operations include a bit (12) to signal the processor to return from the current subroutine.  It also includes two bits (2 and 3) telling the CPU how to adjust the return stack pointer.  If we set bits 12, 3, and 2, leaving all other bits alone, then whatever ALU operation is selected should proceed in parallel with a subroutine return.</p>

<<Definition of [[-alu]]>>=
: +r            pInsn $100C or tweak ;
: -alu          +here>=2 pInsn -alu? if exit then +r r> drop ;

@ All ALU instructions have the topmost three opcode bits set to [[011]].  However, we also want to confirm that bit 12 is clear as well; compiling two EXITs in a row really should produce one adjusted ALU instruction followed by an explicit return (again, remember that the second instruction could be a branch target from somewhere else).</p>

<<Definition of [[-alu?]]>>=
: -alu?         $F000 and $6000 xor ; ( check top 4 bits to verify r->PC bit is clear too )




@ </p>
<h2>C.5.5  Macros</h2>

Once the colon compiler and support for literals work, much of what one thinks of as <q>Forth</q> ends up simply as <i>macros</i> defined in terms of these primitives.  We only think of these resources as primitives because they often ship out of the box with most Forth environments, in some capacity or another.

<h3>C.5.5.1  Buffers</h3>

@ Often, one wants to instantiate a statically-initialized or dynamically managed buffer in the Forth dictionary.  The simplest method involves allocating a chunk of dictionary space, then assigning its starting address to a constant somehow, kind of like this:</p>
<pre>HERE
   /buffer ALLOT
CONSTANT bufferAddress</pre>
<p>While this technique works, it's verbose and incapable of supporting so-called defining words.  However, for our target compiler, it will work nicely, since its static output isn't able to support defining words anyway.</p>
<p>Addressing the verbosity issue, we create a new word [[CREATE]], which encapsulates the above process nicely.  First, we create a new colon definition with whatever name the programmer chooses.  Then, we compile a numeric literal, specifically the address immediately <i>following</i> the full definition.  Then, we terminate the definition, for all we want is the address.  When we're finished, [[there]] will point right after the definition, where the programmer can either allot or place in static literals using [[,]].</p>

<<Macros>>=
: create,       (:) there 4 + lit, (;) ;
<<Target names>>=
: create        create, ;
@ </p>

<h3>C.5.5.2  Control Flow</h3>
<p>A computer which couldn't react to its environment wouldn't be very interesting.  Sometimes, things go wrong which the computer needs to detect.  Other times, a program will need to react to some user input.  Still other times, a program will need to determine if a certain probability has been met.  Each of these cases requires some means of distinguishing between some yes/no situation.  The Machine Forth compiler uses the [[IF]] statement to make these determinations.</p>

<p>The [[IF]] word opens a lexical block, and thus separates two basic blocks in the compiled output.  Since we want the processor to skip over code comprising the consequent, we compile a <i>branch if zero</i> instruction.  However, since we don't yet know where this instruction will point, for we don't yet know how long the consequent will be, we'll preserve the address of the branch instruction on the compiler's data stack.</p>

<<Macros>>=
: if,           there $2000 p, ;
<<Target names>>=
: if            if, ;

@ The [[THEN]] word resolves an outstanding [[IF]]-created lexical block.  It works by patching the branch instruction compiled by [[IF]] to point to the first instruction past the consequent.  As with all program flow instructions, [[THEN]] terminates a basic block, and starts a new one.</p>

<<Macros>>=
: then,         there 2/ $2000 or swap t! bb off ;
<<Target names>>=
: then          then, ;

@ This Machine Forth compiler supports the most basic form of loop &mdash; tail-call-optimized recursion.  A program, knowing how to make a yes-or-no decision, may elect to invoke itself on a subset of its input based on some condition determining whether or not to continue.  This implies that loop bodies need to be separated into their own colon-definitions.  While this seems like a bit of a burden, it's actually a good practice to do anyway, even in systems supporting more Algol-inspired control structures.</p>
<p>In order to find the address of the current definition, we need to consult the symbol table explicitly.  Recall that the current definition is <i>smudged</i>, meaning its name doesn't appear in the programmer-visible symbol table.  Since Forth builds its program image sequentially, we always know that the currently defined word always appears as the most recent symbol to have been defined.</p>
<<Macros>>=
: recurse,      #syms 1- definition call, ;
<<Target names>>=
: recurse       recurse, ;
@ </p>
<h3>C.5.5.3  Machine Primitives</h3>
<p>The J1 microprocessor provides a 1-to-1 mapping from many Forth primitives to single instructions, many of which executes in a single clock cycle.  Below, I list a number of primitives in no particular order.  Unless otherwise documented, the semantics of these primitives match those of eponymously named ANS Forth words.</p>
<<Macros>>=
: drop,         $6103 i, ;
: +,            $6203 i, ;
: and,          $6303 i, ;
: or,           $6403 i, ;
: xor,          $6503 i, ;
: rshift,       $6903 i, ;
: lshift,       $6D03 i, ;
: nop,          $6000 i, ;
: dbg,          $6010 i, ;
: swap,         $6180 i, ;
: dup,          $6081 i, ;
: over,         $6181 i, ;
: nip,          swap, drop, ;
: >r,           $6147 i, ;
: r>,           $6B8D i, ;
: r@,           $6B81 i, ;

<<Target names>>=
: +             +, ;
: dup           dup, ;
: xor           xor, ;
: over          over, ;
: drop          drop, ;
: nop           nop, ;
: rshift        rshift, ;
: lshift        lshift, ;
: and           and, ;
: or            or, ;
: swap          swap, ;
: nip           nip, ;
: >r            >r, ;
: r>            r>, ;
: r@            r@, ;

@ The J1 provides the programmer with two memory accessors, fetch and store.  Due to how the J1 processor interacts with the Xilinx synchronous RAM in the Kestrel-2 computer, both @ and ! need to take two cycles to complete.  The timing for a store operation follows:</p>
<table width="100%" border="1px">
 <thead>
  <th>Cycle</th>
  <th>J1</th>
  <th>RAM</th>
 </thead>
 <tr>
  <td>0</td>
  <td><i>(something places address in T, data in S)</i></td>
  <td>When T updates, RAM address bus changes.  Additionally, when S changes, RAM data input pins change.</td>
 </tr>
 <tr>
  <td>1</td>
  <td><q>Store</q> strobe asserted, while dropping the data stack.</td>
  <td>RAM latches both data and address information, writing the latched data into the specified address.  Meanwhile, the address is removed from the data stack, thus causing the RAM's address bus pins to change state.  Since the Xilinx RAMs are synchronous, this doesn't cause any problems, for the RAM already captured the original address and data bus states.</td>
 </tr>
 <tr>
  <td>2</td>
  <td><q>Store</q> strobe negated, while dropping the data stack.</td>
  <td>This removes the datum stored from the data stack as well.</td>
 </tr>
</table>
<p>Hence, [[!]] is best implemented as an immediate word which compiles two DROPs, one with its write strobe asserted, as follows:</p>
<<Macros>>=
: !,            $6123 i, drop, ;
<<Target names>>=
: !             !, ;
@ Fetching proves slightly more involved.  For starters, its activities occur on opposite clock cycles:</p>
<table width="100%" border="1px">
 <thead>
  <th>Cycle</th>
  <th>J1</th>
  <th>RAM</th>
 </thead>
 <tr>
  <td>0</td>
  <td><i>(something places address in T)</i></td>
  <td>When T updates, RAM address bus changes.</td>
 </tr>
 <tr>
  <td>1</td>
  <td>No operation.</td>
  <td>RAM data outputs become valid during this cycle.</td>
 </tr>
 <tr>
  <td>2</td>
  <td><q>Fetch</q> latches data into T.</td>
  <td>RAM address changes because T changes; however, since the RAMs are synchronous, data remains valid until the following cycle.</td>
 </tr>
</table>
<p>Hence, to properly implement [[@]] for the J1, you need to wait a cycle before latching the data.  This can be achieved using a <i>non-immediate</i> word, like so:</p>
<pre>: @  @, ;</pre>
<p>The [[CALL]] to [[@]] will delay the extra cycle needed for the synchronous RAMs to present valid data on the bus.  The [[@, ;]] sequence will latch the data and resume operation in a single cycle.  Thus, [[CALL @]] will consume exactly two cycles, just what we need to ensure proper RAM timing.</p>
<<Macros>>=
: @,            $6C00 i, ;
@ </p>

<h2>C.6  Vocabulary Selection</h2>
@ It's really inconvenient to have to constantly type commas after primitives and immediate words.  Therefore, we need a way of conveniently alternating between target-specific and host-specific meanings of various words.  We'll exploit vocabularies to achieve this magic.</p>
<<[[TARGET]] and [[HOST]]>>=
only forth definitions
vocabulary target-primitives

: target        only forth also target-primitives ;
: host          only forth ;

@ When the programmer desires to work with the host-defined Forth semantics, he invokes [[HOST]].  When compiling software for the target, [[TARGET]] is used.  For example,</p>
<pre>
HOST
: foo   ." Hello world!" cr ;
TARGET
: foo   ." foo was called" cr ;
: bar   foo ;
HOST
: bar   foo ;
bar  <b>Hello world!</b>
ok
_</pre>
<p>For this to work, the target-specific vocabulary needs separate definitions for the commonly used Forth primitives and macros.  Many of these primitives have already been defined earlier in this document.</p>
<<[[TARGET]] and [[HOST]]>>=
also target-primitives definitions previous
<<Target names>>

@ Some of the <q>primitives</q> are macros, though.</p>

<<[[TARGET]] and [[HOST]]>>=
: 2dup          over, over, ;
: 2drop         drop, drop, ;
: variable      create, 0 ,, ;
: 2*            1 lshift ;
: 2/            1 rshift ;
@ </p>

<h2>C.7  Miscellaneous</h2>
@ The Machine Forth compiler was designed to run under the SwiftForth environment.  However, I find its general lack of a word to find a word in the dictionary given an explicit counted string on the stack rather burdensome.  GForth provides this facility through [[sfind]], whose behavior I replicate below.</p>

<<GForth compatibility layer>>=
: sfind         dup pad c!  pad 1+ swap move  pad find dup 0= if >r count r> then ;

@ Note that if you move this software to GForth, you'll want to remove or otherwise comment the above definition out.</p>

